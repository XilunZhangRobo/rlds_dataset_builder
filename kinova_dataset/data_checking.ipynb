{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os \n",
    "# import cv2\n",
    "\n",
    "# All_data = False\n",
    "\n",
    "# collected_data_feedback_path = 'data/collected_data_feedback.npy'\n",
    "# # collected_data_dpo_path = 'data/new_collected_data_dpo.npy'\n",
    "\n",
    "# ## load data \n",
    "# data = np.load(collected_data_feedback_path, allow_pickle=True).item()\n",
    "# # dpo_data = np.load(collected_data_dpo_path, allow_pickle=True).item()\n",
    "\n",
    "# print (len(data))\n",
    "\n",
    "# filtered_data = {}\n",
    "# max_velocity = 0.2 \n",
    "# min_velocity = -0.2\n",
    "# for key, value in data.items():\n",
    "#     # if not All_data:\n",
    "#     #     if dpo_data[int(str(key).split('_')[-1])] == 0:\n",
    "#     #         continue\n",
    "#     filtered_data[key] = value[\"tool_speed\"] + [value[\"gripper_angle\"]]\n",
    "#     filtered_data[key][3:6] = [0 for x in filtered_data[key][3:6]]\n",
    "\n",
    "\n",
    "# for key, value in filtered_data.items():\n",
    "#     if filtered_data[key][-1] < 0.5:\n",
    "#         filtered_data[key][-1] = -1\n",
    "#     else:\n",
    "#         filtered_data[key][-1] = 1\n",
    "\n",
    "\n",
    "# episode_length = 80\n",
    "# ## load image \n",
    "# image_folder_path = 'data/pngs'\n",
    "# ## load files in order\n",
    "# all_images = {}\n",
    "# for image_path in sorted(os.listdir(image_folder_path)):\n",
    "#     image = cv2.imread(os.path.join(image_folder_path, image_path))\n",
    "#     image_name = image_path.split('.')[0]\n",
    "#     all_images[image_name] = image\n",
    "\n",
    "# for index in range(0, int(len(filtered_data)/episode_length)):\n",
    "#     episode = []\n",
    "#     for step in range(episode_length):\n",
    "#         data_name = list(filtered_data.keys())[index + step]\n",
    "#         episode.append({\n",
    "#             'image':all_images[data_name],\n",
    "#             'action': filtered_data[data_name],\n",
    "#             'language_instruction': 'lift carrot.',\n",
    "#         })\n",
    "  \n",
    "#     # if index < int(0.8 * (len(filtered_data)/episode_length)):\n",
    "#     #     np.save(f'data/training_data_unorm_100/episode_{index}', episode)\n",
    "#     # else:\n",
    "#     #     np.save(f'data/val_data_unorm_100/episode_{index-int(0.8 * (len(filtered_data)/episode_length))}', episode)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data for Finetuning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 6126/30989 [00:30<02:01, 203.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import tqdm \n",
    "## tfds build --overwrite\n",
    "\n",
    "collected_data_feedback_path = 'scripted_data_variation/collected_data_feedback.npy'\n",
    "# collected_data_dpo_path = 'data/new_collected_data_dpo.npy'\n",
    "\n",
    "data_size = 100 \n",
    "assert data_size <= 500\n",
    "\n",
    "## load data \n",
    "data = np.load(collected_data_feedback_path, allow_pickle=True).item()\n",
    "\n",
    "save_dic = {int(i):[] for i in range(0, data_size)}\n",
    "for key in tqdm.tqdm(data):\n",
    "    id_ = key\n",
    "    img_path = f'./scripted_data_variation/pngs/{id_}.png'\n",
    "    image = cv2.imread(img_path)\n",
    "    episode_id = id_.split('_')[-1]\n",
    "    step_id = id_.split('_')[-2]\n",
    "    tool_speed = data[key]['tool_speed']\n",
    "    gripper_angle = data[key]['gripper_angle']\n",
    "    if gripper_angle < 0.5:\n",
    "        gripper_angle = -1\n",
    "    else:\n",
    "        gripper_angle = 1\n",
    "    action = tool_speed + [gripper_angle]\n",
    "    action[3:6] = [0 for x in action[3:6]] # optional\n",
    "    save_dic[int(episode_id)].append({\n",
    "        'image': image,\n",
    "        'action': action,\n",
    "        'language_instruction': 'lift carrot.'\n",
    "    })\n",
    "    if int(episode_id) == data_size-1:\n",
    "        break\n",
    "    \n",
    "# create path if not exists\n",
    "training_path = f'scripted_data_variation/training_data_{data_size}'\n",
    "val_path = f'scripted_data_variation/val_data_{data_size}'\n",
    "os.makedirs(training_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "for episode_key in save_dic:\n",
    "    if len(save_dic[episode_key]) == 0:\n",
    "        continue\n",
    "    if episode_key < int(data_size*0.8):\n",
    "        np.save(training_path + f'/episode_{episode_key}.npy', save_dic[episode_key])\n",
    "    else:\n",
    "        np.save(val_path + f'/episode_{episode_key-int(data_size*0.8)}.npy', save_dic[episode_key])\n",
    "    # print(f'episode_{episode_key} saved')\n",
    "    # print(len(save_dic[episode_key]))\n",
    "print (len(save_dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data for Motion Commands ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 30933/30989 [02:29<00:00, 207.37it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 52.27it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 52.32it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 52.36it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 52.66it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 52.65it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 52.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "import tqdm \n",
    "import random\n",
    "## tfds build --overwrite\n",
    "\n",
    "def get_random_image(folder_path):\n",
    "    with os.scandir(folder_path) as entries:\n",
    "        entries = list(entries)\n",
    "        random_entry = random.choice(entries)\n",
    "        if random_entry.is_file():\n",
    "            image = cv2.imread(random_entry.path)\n",
    "            return image\n",
    "\n",
    "\n",
    "\n",
    "collected_data_feedback_path = 'scripted_data_variation/collected_data_feedback.npy'\n",
    "\n",
    "action_data_size = 500 \n",
    "assert action_data_size <= 500\n",
    "\n",
    "image_folder_path = './scripted_data_variation/pngs/'\n",
    "\n",
    "motion_commands_list = [\"Move left.\", \"Move right.\", \"Move forward.\", \"Move backward.\", \"Move up.\", \"Move down.\"]\n",
    "motion_data_size = 200 * len(motion_commands_list)\n",
    "\n",
    "## load data \n",
    "data = np.load(collected_data_feedback_path, allow_pickle=True).item()\n",
    "\n",
    "save_dic = {int(i):[] for i in range(0, action_data_size + motion_data_size)}\n",
    "data_size = action_data_size + motion_data_size\n",
    "for key in tqdm.tqdm(data):\n",
    "    id_ = key\n",
    "    img_path = image_folder_path + f'{id_}.png'\n",
    "    image = cv2.imread(img_path)\n",
    "    episode_id = id_.split('_')[-1]\n",
    "    step_id = id_.split('_')[-2]\n",
    "    tool_speed = data[key]['tool_speed']\n",
    "    gripper_angle = data[key]['gripper_angle']\n",
    "    if gripper_angle < 0.5:\n",
    "        gripper_angle = -1\n",
    "    else:\n",
    "        gripper_angle = 1\n",
    "    action = tool_speed + [gripper_angle]\n",
    "    action[3:6] = [0 for x in action[3:6]] # optional\n",
    "    save_dic[int(episode_id)].append({\n",
    "        'image': image,\n",
    "        'action': action,\n",
    "        'language_instruction': 'lift carrot.'\n",
    "    })\n",
    "    if int(episode_id) == action_data_size-1:\n",
    "        break\n",
    "\n",
    "## collect data for motion commands only\n",
    "for index, motion_command in enumerate(motion_commands_list):\n",
    "    if motion_command == \"Move left.\":\n",
    "        action = [0, 0.1, 0, 0, 0, 0, 1]\n",
    "    elif motion_command == \"Move right.\":\n",
    "        action = [0, -0.1, 0, 0, 0, 0, 1]\n",
    "    elif motion_command == \"Move forward.\":\n",
    "        action = [0.1, 0, 0, 0, 0, 0, 1]\n",
    "    elif motion_command == \"Move backward.\":\n",
    "        action = [-0.1, 0, 0, 0, 0, 0, 1]\n",
    "    elif motion_command == \"Move up.\":\n",
    "        action = [0, 0, 0.1, 0, 0, 0, 1]\n",
    "    elif motion_command == \"Move down.\":\n",
    "        action = [0, 0, -0.1, 0, 0, 0, 1]\n",
    "    for i in tqdm.tqdm(range(200)):\n",
    "        ## sample a image from image_path_folder\n",
    "        random_image = get_random_image(image_folder_path)\n",
    "        save_dic[action_data_size + index * (i+1)].append({\n",
    "            'image': random_image,\n",
    "            'action': action,\n",
    "            'language_instruction': motion_command\n",
    "        })\n",
    "    \n",
    "# create path if not exists\n",
    "training_path = f'scripted_data_variation/training_data_{action_data_size}'\n",
    "val_path = f'scripted_data_variation/val_data_{action_data_size}'\n",
    "os.makedirs(training_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "for episode_key in save_dic:\n",
    "    if len(save_dic[episode_key]) == 0:\n",
    "        continue\n",
    "    if episode_key < int(data_size*0.8):\n",
    "        np.save(training_path + f'/episode_{episode_key}.npy', save_dic[episode_key])\n",
    "    else:\n",
    "        np.save(val_path + f'/episode_{episode_key-int(data_size*0.8)}.npy', save_dic[episode_key])\n",
    "    # print(f'episode_{episode_key} saved')\n",
    "    # print(len(save_dic[episode_key]))\n",
    "print (len(save_dic))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data for Random Action with Black Images ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "min = -0.2 \n",
    "max = 0.2\n",
    "\n",
    "step = 0.05 \n",
    "save_action = []\n",
    "for x in np.arange(min, max, step):\n",
    "    for y in np.arange(min, max, step):\n",
    "        for z in np.arange(min, max, step):\n",
    "            gripper = 0\n",
    "            save_action.append([x, y, z, 0, 0, 0, gripper])\n",
    "            gripper_ = 1\n",
    "            save_action.append([x, y, z, 0, 0, 0, gripper_])\n",
    "\n",
    "print (len(save_action))\n",
    "\n",
    "episode_len = 40\n",
    "episode_number = len(save_action) // episode_len\n",
    "\n",
    "def create_balck_image():\n",
    "    ## create black image with np.uint8\n",
    "    image_np = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    # save image_np as image type\n",
    "    image = Image.fromarray(image_np)\n",
    "    return image\n",
    "\n",
    "folder_path_training = 'black_data/trianing_data'\n",
    "folder_path_val = 'black_data/val_data'\n",
    "os.makedirs(folder_path_training, exist_ok=True)\n",
    "os.makedirs(folder_path_val, exist_ok=True)\n",
    "\n",
    "for i in range (0, episode_number):\n",
    "    episode = []\n",
    "    for j in range(0, episode_len):\n",
    "        episode.append({\n",
    "            'image': create_balck_image(),\n",
    "            'action': save_action[i*episode_len + j],\n",
    "            'language_instruction': 'lift carrot.'\n",
    "        })\n",
    "    if i < int(0.8 * episode_number):\n",
    "        np.save(folder_path_training + f'/episode_{i}.npy', episode)\n",
    "    else:\n",
    "        np.save(folder_path_val + f'/episode_{i-int(0.8 * episode_number)}.npy', episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1240 // 40\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
