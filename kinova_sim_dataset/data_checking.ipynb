{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for one file ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "## tfds build --overwrite\n",
    "\n",
    "collected_data_feedback_path = 'data/simulation_dataset_1.npy'\n",
    "\n",
    "## load data \n",
    "data = np.load(collected_data_feedback_path, allow_pickle=True).item()\n",
    "episode_length = 80\n",
    "\n",
    "for key, value in data.items():\n",
    "    # print (len(value[\"image\"]))\n",
    "    # print (\"action\", value[\"action\"])\n",
    "    if len(value['image']) < episode_length:\n",
    "        ## pad the data with the 0 antion and last image\n",
    "        last_image = value['image'][-1]\n",
    "        ## save the last_image as a png \n",
    "        # print (last_image.shape)\n",
    "        # cv2.imwrite(f\"last_image_{key}.png\", last_image)\n",
    "        # input()\n",
    "        last_action = np.zeros(7)\n",
    "        for i in range(episode_length - len(value[\"image\"])):\n",
    "            value['image'].append(last_image)\n",
    "            value['action'].append(last_action)\n",
    "    value['image'] = [cv2.cvtColor(np.array(image).astype(np.uint8), cv2.COLOR_BGR2RGB) for image in value['image']]\n",
    "    value['action'] = [np.array(action).astype(np.float32) for action in value['action']]\n",
    "    data[key] = value\n",
    "\n",
    "\n",
    "training_save_path = f'data/training_data_{len(data)}'\n",
    "os.mkdir(training_save_path) if not os.path.exists(training_save_path) else None \n",
    "val_save_path = f'data/validation_data_{len(data)}'\n",
    "os.mkdir(val_save_path) if not os.path.exists(val_save_path) else None\n",
    "\n",
    "for index in range(0, int(len(data))):\n",
    "    episode = []\n",
    "    for step in range(episode_length):\n",
    "        episode.append({\n",
    "            'image': data[f\"data_{index}\"]['image'][step],\n",
    "            'action': data[f\"data_{index}\"]['action'][step],\n",
    "            'language_instruction': 'lift cube',\n",
    "        })\n",
    "    # np.save(training_save_path + f'/episode_{index}', episode)\n",
    "    # np.save(val_save_path + f'/episode_{index}', episode)\n",
    "    if index < int(0.8 * len(data)):\n",
    "        np.save(training_save_path + f'/episode_{index}', episode)\n",
    "    else:\n",
    "        np.save(val_save_path + f'/episode_{index-int(0.8 * len(data))}', episode)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Multiple Data into Training dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139 1928 2114 5181\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "## tfds build --overwrite\n",
    "\n",
    "data_feedback_path_1 = 'data/simulation_dataset_1200.npy'\n",
    "data_feedback_path_2 = 'data/simulation_dataset_2000.npy'\n",
    "data_feedback_path_3 = 'data/simulation_dataset_2200.npy'\n",
    "\n",
    "## load data \n",
    "data_1 = np.load(data_feedback_path_1, allow_pickle=True).item()\n",
    "data_2 = np.load(data_feedback_path_2, allow_pickle=True).item()\n",
    "data_3 = np.load(data_feedback_path_3, allow_pickle=True).item()\n",
    "episode_length = 80\n",
    "\n",
    "## stack all data together\n",
    "data = {}\n",
    "for key, value in data_1.items():\n",
    "    data[key] = value\n",
    "data_length = len(data)\n",
    "for key, value in data_2.items():\n",
    "    number = key.split(\"_\")[1]\n",
    "    data[f\"data_{int(number) + data_length}\"] = value\n",
    "data_length = len(data)\n",
    "for key, value in data_3.items():\n",
    "    number = key.split(\"_\")[1]\n",
    "    data[f\"data_{int(number) + data_length}\"] = value\n",
    "\n",
    "print (len(data_1), len(data_2), len(data_3), len(data))\n",
    "\n",
    "for key, value in data.items():\n",
    "    # print (len(value[\"image\"]))\n",
    "    if len(value['image']) < episode_length:\n",
    "        ## pad the data with the 0 antion and last image\n",
    "        last_image = value['image'][-1]\n",
    "        ## save the last_image as a png \n",
    "        # print (last_image.shape)\n",
    "        # cv2.imwrite(f\"last_image_{key}.png\", last_image)\n",
    "        # input()\n",
    "        last_action = np.zeros(7)\n",
    "        for i in range(episode_length - len(value[\"image\"])):\n",
    "            value['image'].append(last_image)\n",
    "            value['action'].append(last_action)\n",
    "    value['image'] = [cv2.cvtColor(np.array(image).astype(np.uint8), cv2.COLOR_BGR2RGB) for image in value['image']]\n",
    "    value['action'] = [np.array(action).astype(np.float32) for action in value['action']]\n",
    "    data[key] = value\n",
    "\n",
    "\n",
    "training_save_path = f'data/training_data_{len(data)}'\n",
    "os.mkdir(training_save_path) if not os.path.exists(training_save_path) else None \n",
    "val_save_path = f'data/validation_data_{len(data)}'\n",
    "os.mkdir(val_save_path) if not os.path.exists(val_save_path) else None\n",
    "\n",
    "for index, key in enumerate(data.keys()):\n",
    "    episode = []\n",
    "    for step in range(episode_length):\n",
    "        episode.append({\n",
    "            'image': data[key]['image'][step],\n",
    "            'action': data[key]['action'][step],\n",
    "            'language_instruction': 'lift cube',\n",
    "        })\n",
    "    if index < int(0.8 * len(data)):\n",
    "        np.save(training_save_path + f'/episode_{index}', episode)\n",
    "    else:\n",
    "        np.save(val_save_path + f'/episode_{index-int(0.8 * len(data))}', episode)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPO Data Generation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, sample_1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_data):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample_2 \u001b[38;5;129;01min\u001b[39;00m all_data[index:]:\n\u001b[0;32m---> 55\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43msample_1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     56\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_2_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28minput\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import cv2\n",
    "## tfds build --overwrite\n",
    "\n",
    "collected_data_feedback_path = 'data/simulation_dataset_10.npy'\n",
    "\n",
    "## load data \n",
    "data = np.load(collected_data_feedback_path, allow_pickle=True).item()\n",
    "episode_length = 80\n",
    "\n",
    "for key, value in data.items():\n",
    "    # print (len(value[\"image\"]))\n",
    "    # print (\"action\", value[\"action\"])\n",
    "    if len(value['image']) < episode_length:\n",
    "        ## pad the data with the 0 antion and last image\n",
    "        last_image = value['image'][-1]\n",
    "        last_action = np.array([0, 0, 0, 0, 0, 0, -1])\n",
    "        for i in range(episode_length - len(value[\"image\"])):\n",
    "            value['image'].append(last_image)\n",
    "            value['action'].append(last_action)\n",
    "    value['image'] = [cv2.cvtColor(np.array(image).astype(np.uint8), cv2.COLOR_BGR2RGB) for image in value['image']]\n",
    "    value['action'] = [np.array(action).astype(np.float32) for action in value['action']]\n",
    "    data[key] = value\n",
    "\n",
    "\n",
    "training_save_path = f'data/dpo_training_data_{len(data)}'\n",
    "os.mkdir(training_save_path) if not os.path.exists(training_save_path) else None \n",
    "val_save_path = f'data/dpo_validation_data_{len(data)}'\n",
    "os.mkdir(val_save_path) if not os.path.exists(val_save_path) else None\n",
    "\n",
    "all_data = []\n",
    "for index in range(0, int(len(data))):\n",
    "    episode_data = []\n",
    "    for step in range(episode_length):\n",
    "        episode_data.append({\n",
    "            'image': data[f\"data_{index}\"]['image'][step],\n",
    "            'action': data[f\"data_{index}\"]['action'][step],\n",
    "            'language_instruction': 'lift cube',\n",
    "            'reward': data[f\"data_{index}\"]['rewards']\n",
    "        })\n",
    "    all_data.append(episode_data)\n",
    "        \n",
    "all_pairs = {}\n",
    "all_pairs['prompt'] = []\n",
    "all_pairs['chosen'] = []\n",
    "all_pairs['rejected'] = []\n",
    "\n",
    "print (len(all_data))\n",
    "\n",
    "print (all_data[0][0]['image'].shape)\n",
    "\n",
    "for index, sample_1 in enumerate(all_data):\n",
    "    for sample_2 in all_data[index:]:\n",
    "        assert sample_1[0]['image'].all() == sample_2[0]['image'].all()\n",
    "        # take 0 language_instruction because they all the same, take 0 image because we focus on same initial state\n",
    "        all_pairs['prompt'].append([sample_1[0]['language_instruction'], sample_1[0]['image']])\n",
    "        all_pairs['chosen'].append(sample_1['action']) if sample_1['reward'] > sample_2['reward'] else all_pairs['chosen'].append(sample_2['action'])\n",
    "        all_pairs['rejected'].append(sample_2['action']) if sample_1['reward'] > sample_2['reward'] else all_pairs['rejected'].append(sample_1['action'])\n",
    "\n",
    "\n",
    "print (all_pairs)\n",
    "# if index < int(0.8 * len(data)):\n",
    "#     np.save(training_save_path + f'/episode_{index}', episode)\n",
    "# else:\n",
    "#     np.save(val_save_path + f'/episode_{index-int(0.8 * len(data))}', episode)\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
